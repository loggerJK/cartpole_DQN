1. data의 부족이 아닐까?
- replayBuffer가 2000개 이상 충분히 모일때까지 데이터를 모은 후에 훈련을 시키도록 하자
- 특정 step까지만 수행하도록 하는 것이 아니라 게임이 종료될때까지 하도록 해보자

2. seed를 고정해야 함


1. 다른 점
- target_network를 업데이트할 때 가중치를 섞어서 업데이트 하는 경우가 있지만 본 코드에는 적용하지 않음
- 


- 참고링크
  - [Tensorflow2로 만든 DQN 코드: CartPole-v1](https://pasus.tistory.com/133)
  - [Deep Q-learning으로 뱀 게임 인공지능 만들기](https://www.secmem.org/blog/2020/02/08/snake-dqn/)